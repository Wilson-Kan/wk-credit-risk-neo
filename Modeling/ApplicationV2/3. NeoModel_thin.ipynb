{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edda73e9-8731-4218-9471-6026953c3755",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "start_from_pickle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65f1e526-626f-40e5-b0dc-1f93595f4aa2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "if not start_from_pickle:\n",
    "    with open(\n",
    "        \"/Workspace/Users/wilson.kan@neofinancial.com/pkls/appl_neo_v2_modeling_ready.pkl\",\n",
    "        \"wb\",\n",
    "    ) as f:  # open a text file\n",
    "        pickle.dump(modeling_dummy_df, f)\n",
    "else:\n",
    "    with open(\n",
    "        \"/Workspace/Users/wilson.kan@neofinancial.com/pkls/appl_neo_v2_modeling_ready.pkl\",\n",
    "        \"rb\",\n",
    "    ) as f:  # Correctly opening the file in binary read mode\n",
    "        modeling_dummy_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b55ed19-a68e-449d-bbac-d338ea92bea2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "modeling_oot = modeling_dummy_df[\n",
    "    modeling_dummy_df[\"month_end\"].isin(\n",
    "        [np.datetime64(\"2023-06-30\"), np.datetime64(\"2023-07-31\")]\n",
    "    )\n",
    "]\n",
    "modeling_intime = modeling_dummy_df[\n",
    "    modeling_dummy_df[\"month_end\"] < np.datetime64(\"2023-06-30\")\n",
    "]\n",
    "modeling_intime = modeling_dummy_df[\n",
    "    modeling_dummy_df[\"month_end\"] > np.datetime64(\"2022-12-31\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4fd1de9-b9ee-476e-9374-2749566534f8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Modeling only thick\n",
    "\n",
    "modeling_oot = modeling_oot[modeling_oot[\"thin\"] == 1]\n",
    "modeling_intime = modeling_intime[modeling_intime[\"thin\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b746ad5-11f5-4a02-bf4d-0c401d2e858e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dropping duplicated features\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    modeling_intime.drop([\"month_end\", \"isdefault_1y\", \"originalCreditScore\", \"GO17\"], axis=1),\n",
    "    modeling_intime[\"isdefault_1y\"],\n",
    "    test_size=0.2, random_state=459339\n",
    ")\n",
    "# create model instance\n",
    "bst = XGBClassifier(\n",
    "    n_estimators=100, max_depth=6, colsample_bytree = 0.75, subsample = 0.5, gamma = 1, eta = 0.1, min_child_weight = 2, objective=\"binary:logistic\", random_state=939180\n",
    ")\n",
    "# fit model\n",
    "bst.fit(X_train, y_train, verbose=True, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=[(X_test, y_test)])\n",
    "xgb.plot_importance(bst)\n",
    "# make predictions\n",
    "# preds = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81eafc82-535a-4641-93b0-cac18378b714",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "feature_imp = []\n",
    "\n",
    "for i in range(len(bst.feature_importances_)):\n",
    "    feature_imp.append((bst.feature_names_in_[i], bst.feature_importances_[i]))\n",
    "\n",
    "feature_imp.sort(key=lambda tup: tup[1], reverse=True)\n",
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3bbc7d2-b159-43ca-82d4-d5981dca4bd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "top_set = []\n",
    "for i in range(20):\n",
    "  top_set.append(feature_imp[i][0])\n",
    "print(top_set)\n",
    "# create model instance\n",
    "bst = XGBClassifier(\n",
    "    n_estimators=100, max_depth=6, colsample_bytree = 0.75, subsample = 0.5, gamma = 1, eta = 0.1, min_child_weight = 2, random_state=4916\n",
    ")\n",
    "# fit model\n",
    "bst.fit(X_train[top_set], y_train, early_stopping_rounds=10, eval_metric=\"auc\", eval_set=[(X_test[top_set], y_test)])\n",
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf72fb9-7bc7-4c69-857b-33f469a26d0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "x_train_scr = bst.predict_proba(X_train[top_set])\n",
    "x_test_scr = bst.predict_proba(X_test[top_set])\n",
    "x_oot_scr = bst.predict_proba(modeling_oot[top_set])\n",
    "print(\"train\", 2*roc_auc_score(y_train, x_train_scr[:, 1])-1)\n",
    "print(\"test\", 2*roc_auc_score(y_test, x_test_scr[:, 1])-1)\n",
    "print(\"oot\", 2*roc_auc_score(modeling_oot[\"isdefault_1y\"], x_oot_scr[:, 1])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6e5ad8-af2d-438b-824e-46f46d636b94",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# sp = modeling_dummy_df[modeling_dummy_df[\"subprime\"] == 1]\n",
    "thin = modeling_dummy_df[modeling_dummy_df[\"thin\"] == 1]\n",
    "# thick = modeling_dummy_df[\n",
    "#     modeling_dummy_df[\"subprime\"] + modeling_dummy_df[\"thin\"] == 0\n",
    "# ]\n",
    "# x_subprime_scr = bst.predict_proba(sp[top_set])\n",
    "x_thin_scr = bst.predict_proba(thin[top_set])\n",
    "# x_thick_scr = bst.predict_proba(thick[top_set])\n",
    "# print(\"subprime\", 2*roc_auc_score(sp[\"isdefault_1y\"], x_subprime_scr[:, 1])-1)\n",
    "print(\"thin\", 2*roc_auc_score(thin[\"isdefault_1y\"], x_thin_scr[:, 1])-1)\n",
    "# print(\"thick\", 2*roc_auc_score(thick[\"isdefault_1y\"], x_thick_scr[:, 1])-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c8bb07-f51b-40a7-a8ce-7e745c95246b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "3. NeoModel_thin",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
