{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f19fff9-30d5-4dc1-9c98-42951fa42210",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import data_model as dm\n",
    "import importlib\n",
    "\n",
    "import mlflow.statsmodels\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, RocCurveDisplay, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import mlflow\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71945c49-3e69-4322-9a0a-02d2cabafe46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "design_matrix = dm.main(spark).where(F.col(\"isSelfCureMonth\") == 0)\n",
    "design_matrix_pd = design_matrix.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d63a5282-e7db-4361-8f9a-06093ee260ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot(predicted, title, Y_test, plt, axis_lim=None):\n",
    "  # predicted = model.predict_proba(X_test)[:,1]\n",
    "  Y_test = Y_test.astype(int)\n",
    "  fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "  axes = axes.ravel()\n",
    "  roc_plot = RocCurveDisplay.from_predictions(Y_test, predicted, ax=axes[0])\n",
    "  axes[0].set_title(\"ROC curve\")\n",
    "  \n",
    "  #create precision recall curve\n",
    "  precision, recall, thresholds = precision_recall_curve(Y_test, predicted)\n",
    "  ap_score = round(average_precision_score(y_true=Y_test,y_score=predicted), 2)\n",
    "  axes[1].plot(recall, precision, color='purple', label = f\"Classifier (AP={ap_score}\")\n",
    "  #add axis labels to plot\n",
    "  axes[1].set_title('Precision-Recall Curve')\n",
    "  axes[1].set_ylabel('Precision')\n",
    "  axes[1].set_xlabel('Recall')\n",
    "  axes[1].legend()\n",
    "\n",
    "  data = pd.DataFrame([np.array(Y_test).T, np.array(predicted)]).T\n",
    "  data=data.astype(float)\n",
    "  data.columns = [\"class\", \"prob\"]\n",
    "  for label, df in data.groupby('class'):\n",
    "    df.prob.plot.kde(label=label, ax=axes[2])\n",
    "    axes[2].legend()\n",
    "    df.prob.hist(alpha=0.4, label=label, ax=axes[3], bins=25)\n",
    "    axes[3].legend()\n",
    "  axes[2].set_title(\"Probability Density Function Estimation\")\n",
    "  axes[3].set_title(\"Raw Probability Histogram\")\n",
    "  if axis_lim:\n",
    "    axes[3].set_ylim(axis_lim)\n",
    "  plt.suptitle(title, fontsize=20)\n",
    "  plt.tight_layout()\n",
    "  return fig\n",
    "\n",
    "\n",
    "def plot_pr_curve(precision, recall, thresholds, ap_score):\n",
    "    x = recall[:-1]\n",
    "    y = precision[:-1]\n",
    "    z = thresholds\n",
    "\n",
    "    # Create a line trace\n",
    "    trace = go.Scatter(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        mode='lines+markers',\n",
    "        hovertemplate='<b>Recall:</b> %{x}<br><b>Precision:</b> %{y}<br><b>threshold:</b> %{customdata}<extra></extra>',\n",
    "        customdata=z  # Pass the third dimension data\n",
    "    )\n",
    "\n",
    "    # Create a layout\n",
    "    layout = go.Layout(\n",
    "        title='Precision-Recall Curve',\n",
    "        xaxis=dict(title='recall'),\n",
    "        yaxis=dict(title='precision'),\n",
    "        width=800,\n",
    "        height=600,\n",
    "          annotations=[\n",
    "          dict(\n",
    "              xref='x',\n",
    "              yref='y',\n",
    "              x=1,\n",
    "              y=1,\n",
    "              text=f\"average precision: {ap_score}\",\n",
    "              showarrow=False,\n",
    "          ),\n",
    "          ]\n",
    "    )\n",
    "\n",
    "    # Create a figure\n",
    "    fig = go.Figure(data=[trace], layout=layout)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c15f755-d6f7-4591-a314-cc7433af434f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "out_of_time_start = dt.date.fromisoformat(\"2022-09-01\").strftime(\"%Y-%m-%d\")\n",
    "in_time_start = dt.date.fromisoformat(\"2023-01-01\").strftime(\"%Y-%m-%d\")\n",
    "in_time_stop = dt.date.fromisoformat(\"2023-11-01\").strftime(\"%Y-%m-%d\")\n",
    "out_of_time_stop = dt.date.fromisoformat(\"2024-03-01\").strftime(\"%Y-%m-%d\")\n",
    "\n",
    "categorical = [\n",
    "    \"brand\",\n",
    "    \"creditScoreBucket\",\n",
    "    \"creditFileBucket\",\n",
    "    \"employmentStatus\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dd7660c-f8ba-4a22-8660-0f1e2ed192b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "_train_dm = design_matrix_pd.where(design_matrix_pd[\"lastDayOfMonth\"].between(in_time_start, in_time_stop))\n",
    "train_dm = pd.get_dummies(_train_dm, columns=categorical, drop_first=True, dummy_na=True).where(_train_dm[\"isSelfCureMonth\"] ==  0).dropna(subset=[\"isSelfCureMonth\"])\n",
    "\n",
    "_oot_dm = design_matrix_pd.where(design_matrix_pd[\"lastDayOfMonth\"].between(out_of_time_start, in_time_start) | design_matrix_pd[\"lastDayOfMonth\"].between(in_time_stop, out_of_time_stop))\n",
    "oot_dm = pd.get_dummies(_oot_dm, columns=categorical, drop_first=True, dummy_na=True).where(_oot_dm[\"isSelfCureMonth\"] ==  0).dropna(subset=[\"isSelfCureMonth\"])\n",
    "\n",
    "_full_dm = design_matrix_pd.where(design_matrix_pd[\"lastDayOfMonth\"].between(out_of_time_start, out_of_time_stop))\n",
    "full_dm = pd.get_dummies(_full_dm, columns=categorical, drop_first=True, dummy_na=True).where(design_matrix_pd[\"isSelfCureMonth\"] ==  0).dropna(subset=[\"isSelfCureMonth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7860288b-7d05-4973-bfc4-a47a05c3e0c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "to_drop = [\"isSelfCureMonth\", \"isSelfCureNextMonth\", \"lastDayOfMonth\", \"creditAccountId\"]\n",
    "X = train_dm.drop(to_drop, axis = 1)\n",
    "Y = train_dm[\"isSelfCureNextMonth\"].fillna(0)\n",
    "\n",
    "oot_X = oot_dm.drop(to_drop, axis = 1)\n",
    "oot_Y = oot_dm[\"isSelfCureNextMonth\"].fillna(0)\n",
    "\n",
    "full_X = full_dm.drop(to_drop, axis = 1)\n",
    "full_Y = full_dm[\"isSelfCureNextMonth\"].fillna(0) \n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, stratify=Y, random_state=2024\n",
    ")     \n",
    "dpds = [(0,180),(0,90),(90,180)]\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    evaluations_model = RandomForestClassifier().fit(X_train, Y_train.astype(int))\n",
    "\n",
    "\n",
    "    test_dm = X_test.copy(deep=True)\n",
    "    test_dm[\"isSelfCureNextMonth\"] = Y_test\n",
    "\n",
    "    for dpd in dpds:\n",
    "        title =  f\"In Time Train Test Split {dpd}\"\n",
    "        test_data = test_dm.where(test_dm.delinquencyDaysPastDue.between(*dpd)).dropna(subset=[\"delinquencyDaysPastDue\"])\n",
    "        X_test = test_data.drop(\"isSelfCureNextMonth\", axis = 1)\n",
    "        Y_test = test_data[\"isSelfCureNextMonth\"]\n",
    "        predicted = evaluations_model.predict_proba(X_test)[:,1]\n",
    "        precision, recall, thresholds = precision_recall_curve(Y_test, predicted)\n",
    "        ap_score = round(average_precision_score(Y_test, predicted),2)\n",
    "        fig1 = plot(predicted, title, Y_test, plt, axis_lim=None)\n",
    "        fig2 = plot_pr_curve(precision, recall, thresholds, ap_score)\n",
    "    \n",
    "        mlflow.log_figure(fig1, f'{title}.png')\n",
    "        mlflow.log_figure(fig2, f\"{dpd}_precision_recall_interactive.html\")\n",
    "    \n",
    "    title =  \"Out Of Time Test\"\n",
    "    predicted = evaluations_model.predict_proba(oot_X)[:,1]\n",
    "    precision, recall, thresholds = precision_recall_curve(oot_Y, predicted)\n",
    "    ap_score = round(average_precision_score(oot_Y, predicted),2)\n",
    "    fig1 = plot(predicted, title, oot_Y, plt, axis_lim=None)\n",
    "    fig2 = plot_pr_curve(precision, recall, thresholds, ap_score)\n",
    "\n",
    "    mlflow.log_figure(fig1, f'{title}.png')\n",
    "    mlflow.log_figure(fig2, \"oot_precision_recall_interactive.html\")\n",
    "\n",
    "    del(evaluations_model)\n",
    "\n",
    "    mlflow.sklearn.autolog(log_model_signatures=True, log_input_examples=True, silent=True)\n",
    "    final_model = RandomForestClassifier().fit(full_X, full_Y.astype(int))\n",
    "    print(\"\\nRandom forest model fitted\")\n",
    "    mlflow.sklearn.log_model(final_model, \"model\")\n",
    "    print(run.info.run_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "train",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
